{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tashaphyne.arabic_const as arabconst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('ar_dataset.csv')\n",
    "df2 = pd.read_csv('L-HSAB', sep='\\t')\n",
    "df3 = pd.read_excel('TweetClassification-Summary.xlsx')\n",
    "df4 = pd.read_excel('AJCommentsClassification-CF.xlsx')\n",
    "lexicon = pd.read_csv('C:\\\\Users\\\\Solom\\\\Desktop\\\\hurtlex_AR.tsv', sep='\\t')\n",
    "lemmas = set(lexicon['lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_lexicon = pd.read_csv('hurtlex_AR.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Solom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\Solom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\Solom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Solom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "for idx,label in enumerate(df1['sentiment']):\n",
    "    if 'hateful' in label:\n",
    "        df1['sentiment'][idx] = 'hateful'\n",
    "    elif 'offensive' in label:\n",
    "        df1['sentiment'][idx] = 'offensive'\n",
    "    elif 'abusive' in label:\n",
    "        df1['sentiment'][idx] = 'hateful'\n",
    "    elif 'fearful' in label:\n",
    "        df1['sentiment'][idx] = 'hateful'\n",
    "    elif 'disrespectful' in label:\n",
    "        df1['sentiment'][idx] = 'hateful'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,label in enumerate(df2['Class']):\n",
    "    if 'hate' in label:\n",
    "        df2['Class'][idx] = 'hateful'\n",
    "    elif 'abusive' in label:\n",
    "        df2['Class'][idx] = 'offensive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\Solom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\Solom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\Solom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for idx,label in enumerate(df3['aggregatedAnnotation']):\n",
    "    if label == -2:\n",
    "        df3['aggregatedAnnotation'][idx] = 'hateful'\n",
    "    elif label == -1:\n",
    "        df3['aggregatedAnnotation'][idx] = 'offensive'\n",
    "    elif label == 0:\n",
    "        df3['aggregatedAnnotation'][idx] = 'normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Solom\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for idx, body in enumerate(df4['body']):\n",
    "    if df4['languagecomment'][idx]== -1 or df4['languagecomment'][idx]==-2:\n",
    "        df4['languagecomment'][idx] = 'hateful'\n",
    "    elif df4['languagecomment'][idx]==0:\n",
    "        df4['languagecomment'][idx] = 'normal'\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1[['tweet', 'sentiment']], df2.rename(columns={\"Tweet\":\"tweet\",\"Class\": \"sentiment\"}),\n",
    "          df3[['text', 'aggregatedAnnotation']].rename(columns={\"text\":\"tweet\",\"aggregatedAnnotation\": \"sentiment\"}),\n",
    "         df4[['body', 'languagecomment']].rename(columns={\"body\":\"tweet\", \"languagecomment\":\"sentiment\"})]\n",
    "df = pd.concat(frames, join='outer', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hateful', 'normal', 'offensive'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41881"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeArabic(text):\n",
    "    # Remove Tashkeel\n",
    "    text = arabconst.HARAKAT_PAT.sub('', text)\n",
    "    # Remove Repeated Characters\n",
    "    text = re.sub(r'(.)\\1+', r'\\1', text)\n",
    "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [normalizeArabic(x) for x in stopwords.words('arabic')]\n",
    "st = ISRIStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_single_chars(text):\n",
    "    words = text.split(\" \")\n",
    "    text = \" \".join([word for word in words if len(word) > 1])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = normalizeArabic(text)\n",
    "    # Remove Punctuations\n",
    "    arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "    english_punctuations = string.punctuation\n",
    "    punctuations_list = arabic_punctuations + english_punctuations\n",
    "    text = text.translate(str.maketrans('', '', punctuations_list))\n",
    "    # Remove Hashtag Signs\n",
    "    text = re.sub(r\"#\", \" \", text)\n",
    "    # Remove URLs, Mentions, Trailing Non-Whitespaces Characters\n",
    "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \" \", text)\n",
    "    # Remove Numbers\n",
    "    text = re.sub(r\"\\d+\", \" \", text)\n",
    "    # Remove English Characters\n",
    "    text = re.sub(r\"[A-Z|a-z]+\", \" \", text)\n",
    "    # Remove Single Characters\n",
    "    text = remove_single_chars(text)\n",
    "    # Remove Stop Words\n",
    "    text = \" \".join([word for word in word_tokenize(text) if not word in stop_words])\n",
    "    return str(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    # Stemming\n",
    "    text = \" \".join([st.stem(word)for word in word_tokenize(text)])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean'] = df['tweet'].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmed'] = df['clean'].apply(lambda x: stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon['clean'] = lexicon['lemma'].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon['stem'] = lexicon['clean'].apply(lambda x: stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_lexicon['clean'] = old_lexicon['lemma'].apply(lambda x: clean(x))\n",
    "old_lexicon['stem'] = old_lexicon['clean'].apply(lambda x: stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'صلاة الفجر خير لك من ترديد بول البعير وسبي النساء واغتصاب طفلة نظافة ونشاط وحيوية #عقلانيون'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'صلاه الفجر خير ترديد بول البعير وسبي النساء واغتصاب طفله نظافه ونشاط وحيويه عقلانيون'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_value = float(\"NaN\")\n",
    "old_lexicon.replace(\"\", nan_value, inplace=True)\n",
    "old_lexicon.dropna(subset = [\"clean\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>pos</th>\n",
       "      <th>category</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>lemma</th>\n",
       "      <th>level</th>\n",
       "      <th>clean</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AR1499</td>\n",
       "      <td>n</td>\n",
       "      <td>an</td>\n",
       "      <td>no</td>\n",
       "      <td>الأوروبية الآسيوية غريفون</td>\n",
       "      <td>inclusive</td>\n",
       "      <td>الاوروبيه الاسيويه غريفون</td>\n",
       "      <td>ورب سيه غرف</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AR1048</td>\n",
       "      <td>n</td>\n",
       "      <td>cds</td>\n",
       "      <td>no</td>\n",
       "      <td>ديماجوجي</td>\n",
       "      <td>conservative</td>\n",
       "      <td>ديماجوجي</td>\n",
       "      <td>ديماجوجي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>AR70</td>\n",
       "      <td>n</td>\n",
       "      <td>om</td>\n",
       "      <td>no</td>\n",
       "      <td>اللواطة</td>\n",
       "      <td>inclusive</td>\n",
       "      <td>الواطه</td>\n",
       "      <td>وطه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>AR2743</td>\n",
       "      <td>n</td>\n",
       "      <td>dmc</td>\n",
       "      <td>yes</td>\n",
       "      <td>تشرد</td>\n",
       "      <td>inclusive</td>\n",
       "      <td>تشرد</td>\n",
       "      <td>شرد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>AR1322</td>\n",
       "      <td>n</td>\n",
       "      <td>qas</td>\n",
       "      <td>no</td>\n",
       "      <td>الفلاح</td>\n",
       "      <td>inclusive</td>\n",
       "      <td>الفلاح</td>\n",
       "      <td>فلح</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>AR2310</td>\n",
       "      <td>n</td>\n",
       "      <td>an</td>\n",
       "      <td>no</td>\n",
       "      <td>دُودَة</td>\n",
       "      <td>inclusive</td>\n",
       "      <td>دوده</td>\n",
       "      <td>دود</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>AR931</td>\n",
       "      <td>n</td>\n",
       "      <td>an</td>\n",
       "      <td>no</td>\n",
       "      <td>التنصت</td>\n",
       "      <td>inclusive</td>\n",
       "      <td>التنصت</td>\n",
       "      <td>تنص</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>AR948</td>\n",
       "      <td>n</td>\n",
       "      <td>an</td>\n",
       "      <td>no</td>\n",
       "      <td>مغناج</td>\n",
       "      <td>conservative</td>\n",
       "      <td>مغناج</td>\n",
       "      <td>غنج</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      id pos category stereotype                      lemma  \\\n",
       "0      0  AR1499   n       an         no  الأوروبية الآسيوية غريفون   \n",
       "1      1  AR1048   n      cds         no                   ديماجوجي   \n",
       "2      2    AR70   n       om         no                    اللواطة   \n",
       "3      3  AR2743   n      dmc        yes                       تشرد   \n",
       "4      4  AR1322   n      qas         no                     الفلاح   \n",
       "5      5  AR2310   n       an         no                     دُودَة   \n",
       "6      6   AR931   n       an         no                     التنصت   \n",
       "7      9   AR948   n       an         no                      مغناج   \n",
       "\n",
       "          level                      clean         stem  \n",
       "0     inclusive  الاوروبيه الاسيويه غريفون  ورب سيه غرف  \n",
       "1  conservative                   ديماجوجي     ديماجوجي  \n",
       "2     inclusive                     الواطه          وطه  \n",
       "3     inclusive                       تشرد          شرد  \n",
       "4     inclusive                     الفلاح          فلح  \n",
       "5     inclusive                       دوده          دود  \n",
       "6     inclusive                     التنصت          تنص  \n",
       "7  conservative                      مغناج          غنج  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_lexicon.reset_index().head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_lexicon.reset_index().to_csv('old_lexicon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\"\", nan_value, inplace=True)\n",
    "df.dropna(subset = [\"clean\"], inplace=True)\n",
    "df.reset_index().to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon.replace(\"\", nan_value, inplace=True)\n",
    "lexicon.dropna(subset = [\"clean\"], inplace=True)\n",
    "lexicon.reset_index().to_csv('New_Lexicon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
